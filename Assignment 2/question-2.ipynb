{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\nmodel = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\nprompt = \"IIT Bombay is one of the best Institute\"\n\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n\ngen_tokens = model.generate(\n    input_ids,\n    do_sample=True,\n    temperature=0.9,\n    max_length=100,\n)\ngen_text_GPT = tokenizer.batch_decode(gen_tokens)[0]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-14T11:55:12.693761Z","iopub.execute_input":"2024-06-14T11:55:12.694337Z","iopub.status.idle":"2024-06-14T11:55:31.601225Z","shell.execute_reply.started":"2024-06-14T11:55:12.694306Z","shell.execute_reply":"2024-06-14T11:55:31.600176Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d790ea8f021c4d559af223f2bd13132a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9440f7bbfbcb4f4fbc843d938f534c9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f110ac16010e4c91a121379469cdc0f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14f017e2514d41359506b204c6a646dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91f32a03d57947009538dbdecdf43b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"978455eaeadf4ef0ad47ce5f3b8f3a15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d022b4cd6fa148e184569e9606cc0cc0"}},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"gen_text_GPT","metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:55:31.613418Z","iopub.execute_input":"2024-06-14T11:55:31.613764Z","iopub.status.idle":"2024-06-14T11:55:31.798219Z","shell.execute_reply.started":"2024-06-14T11:55:31.613714Z","shell.execute_reply":"2024-06-14T11:55:31.797263Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'IIT Bombay is one of the best Institute of Social Sciences in India. It has a huge reputation and in this regard, I am pleased to mention it, as it is one of the most prestigious institutes of study in the country. I have heard that the President of the Institute is P.S. Narayanan who was born there.\\n\\nThis report is submitted as part of the ongoing inquiry and is submitted by an independent journalist to the Board of Directors of Bombay State Government. It'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"lmsys/vicuna-7b-v1.5\")\nmodel = AutoModelForCausalLM.from_pretrained(\"lmsys/vicuna-7b-v1.5\")\nprompt = \"IIT Bombay is one of the best Institute\"\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\ngenerate_ids = model.generate(inputs.input_ids, max_length=100)\ngen_text_vicuna= tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:55:41.930105Z","iopub.execute_input":"2024-06-14T11:55:41.930814Z","iopub.status.idle":"2024-06-14T11:59:12.231762Z","shell.execute_reply.started":"2024-06-14T11:55:41.930771Z","shell.execute_reply":"2024-06-14T11:59:12.230871Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f183eb3333f442b8512f6025c1439a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a25f4ea9dc2e4ae583b51ea35dcbde4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02154139dde94210a38eed2debe06019"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b52021bf313447997284e3fd79e7e93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a7fbf69e7f949e5bae021c17a9cceed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad90f2b69f9c4fd4ae00f8a921b3d256"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a0348711d941b5a7a26dd7259b226c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14c881886c34aa8b2b25b00ea60dc50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f961d5fba3448f8758cb29b867ab46"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4d6a9d21cd64d7eb5afb180ac13c19a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"gen_text_vicuna","metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:59:39.304074Z","iopub.execute_input":"2024-06-14T11:59:39.304715Z","iopub.status.idle":"2024-06-14T11:59:39.310208Z","shell.execute_reply.started":"2024-06-14T11:59:39.304685Z","shell.execute_reply":"2024-06-14T11:59:39.309299Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'IIT Bombay is one of the best Institute in India for Engineering and Technology. nobody can deny this fact. But the problem is that the placement record of IIT Bombay is not that good as compared to other IITs. The reason behind this is that the number of students appearing for placements is very high and the number of companies visiting IIT Bombay is limited.\\n\\nHowever, this does not mean that students of IIT Bombay are not'"},"metadata":{}}]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-1.5B-Instruct\")\nmodel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-1.5B-Instruct\")\n\nprompt = \"IIT Bombay is one of the best Institute\"\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Generate\ngenerate_ids = model.generate(inputs.input_ids, max_length=100)\ngen_text_microsoft= tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:55:49.815325Z","iopub.execute_input":"2024-06-14T13:55:49.816039Z","iopub.status.idle":"2024-06-14T13:56:52.356628Z","shell.execute_reply.started":"2024-06-14T13:55:49.816002Z","shell.execute_reply":"2024-06-14T13:56:52.355750Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23349108281b4a7ca320ed9a5d25aae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02e63cc1dbe348fd9599009b0e4ee13d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da95c10d4d44e289fc1a6ecc941e251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aae662eefc54ba89ca29fe0bbfa40f4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8f600810dce4ab0adb2f1786529371f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"200c5684eebc4e7abd0d455767bafead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c9ffe4d02364c138a3432d479db06ae"}},"metadata":{}}]},{"cell_type":"code","source":"gen_text_microsoft","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:58:19.913755Z","iopub.execute_input":"2024-06-14T13:58:19.914163Z","iopub.status.idle":"2024-06-14T13:58:19.920709Z","shell.execute_reply.started":"2024-06-14T13:58:19.914135Z","shell.execute_reply":"2024-06-14T13:58:19.919698Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'IIT Bombay is one of the best Institute for engineering in India. It was established by the Government of India and it is located in Mumbai, Maharashtra.\\nIt offers undergraduate courses in various disciplines like Mechanical Engineering, Electrical Engineering, Civil Engineering, Chemical Engineering etc. The institute also provides postgraduate courses in these disciplines.\\nThe campus of IIT Bombay is spread over 500 acres and it has a number of buildings with modern infrastructure facilities. The college has well-equipped laboratories, libraries, computer labs'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/wavecoder-ultra-6.7b\")\nmodel = AutoModelForCausalLM.from_pretrained(\"microsoft/wavecoder-ultra-6.7b\")\n\nprompt = \"IIT Bombay is one of the best Institute\"\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Generate\ngenerate_ids = model.generate(inputs.input_ids, max_length=100)\ngen_text_microsoft= tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_text_microsoft","metadata":{"execution":{"iopub.status.busy":"2024-06-14T12:14:07.436108Z","iopub.execute_input":"2024-06-14T12:14:07.436650Z","iopub.status.idle":"2024-06-14T12:14:07.444592Z","shell.execute_reply.started":"2024-06-14T12:14:07.436622Z","shell.execute_reply":"2024-06-14T12:14:07.443663Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'IIT Bombay is one of the best Institute of Technology in India. It is located in the heart of IT city, Bangalore. It offers various courses like B.Tech, M.Tech, MCA, MBA, BCA, BBA, B.Sc, M.Sc, M.A, Ph.D etc.\\n\\n\\nIIT Bombay is ranked among the top universities in India for engineering and technology programs. It is a'"},"metadata":{}}]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"mlabonne/NeuralDaredevil-8B-abliterated\")\nmodel = AutoModelForCausalLM.from_pretrained(\"mlabonne/NeuralDaredevil-8B-abliterated\")\n\nprompt = \"Hey, are you conscious? Can you talk to me?\"\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Generate\ngenerate_ids = model.generate(inputs.input_ids, max_length=30)\ntokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:49:55.078376Z","iopub.execute_input":"2024-06-14T13:49:55.079180Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eddf5b1188a46ac980b7b340f3385c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a02e8878aff47d0a615dc8e32dd05f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06403b409ac44d9ab9f6e45a0ad2baa5"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd3ae040eb444d5d9b45a8505c9be750"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6ddf75a1fd42918facfe1541a3c30b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc523fbe17424b0d84f937337c4e6f28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b4acf2876e4f3b8dcced35839a8597"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11728289eacb4f77887a2dd8d8f4dc7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fd5cd7d84f04237916b332c8e0f6154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d4a3c270291499684bc65c6ace61a9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d63d75ec48a4e2aa0b632064baa2e23"}},"metadata":{}}]},{"cell_type":"code","source":"gen_text_qwen","metadata":{"execution":{"iopub.status.busy":"2024-06-14T13:11:36.970841Z","iopub.execute_input":"2024-06-14T13:11:36.971767Z","iopub.status.idle":"2024-06-14T13:11:37.322347Z","shell.execute_reply.started":"2024-06-14T13:11:36.971729Z","shell.execute_reply":"2024-06-14T13:11:37.321155Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgen_text_qwen\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'gen_text_qwen' is not defined"],"ename":"NameError","evalue":"name 'gen_text_qwen' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}